# utils/ai_locator.py
import os
import cv2
import easyocr
from ultralytics import YOLO
from pathlib import Path

class AILocator:
    def __init__(self, model_path="runs/detect/train/weights/best.pt"):
        # 1. ëª¨ë¸ ê²½ë¡œ ê²€ì¦ ë° ë¡œë“œ
        self.model_path = Path(model_path).resolve()
        if not self.model_path.exists():
            raise FileNotFoundError(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        print(f"â³ YOLO ëª¨ë¸ ë¡œë”© ì¤‘... ({self.model_path.name})")
        self.model = YOLO(str(self.model_path))
        
        # 2. EasyOCR ì—”ì§„ ë¡œë“œ (GPU í™œì„±í™”)
        print("â³ OCR ì—”ì§„ ë¡œë”© ì¤‘ (GPU í™œì„±í™”)...")
        self.reader = easyocr.Reader(['en', 'ko'], gpu=True)
        
        # 3. í´ë˜ìŠ¤ ë§¤í•‘ (data.yaml ê¸°ì¤€)
        self.class_map = {'button': 0, 'input': 1, 'link': 2}

    def click_by_text(self, page, target_text, target_class="button", conf=0.01):
        """YOLOë¡œ ê°ì²´ë¥¼ ì°¾ê³  OCRë¡œ í…ìŠ¤íŠ¸ë¥¼ ëŒ€ì¡°í•˜ì—¬ í´ë¦­í•©ë‹ˆë‹¤."""
        
        # 1. ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ (ì ˆëŒ€ ê²½ë¡œ)
        screenshot_path = Path("inference_temp.png").resolve()
        page.screenshot(path=str(screenshot_path))
        
        save_dir = Path("runs/detect").resolve()
        
        # 2. YOLO ì¶”ë¡  (í•´ë‹¹ í™”ë©´ì—ì„œ ê°ì²´ë“¤ ì°¾ê¸°)
        results = self.model.predict(
            source=str(screenshot_path),
            conf=conf,
            imgsz=640,
            save=True,
            project=str(save_dir),
            name="predict",
            exist_ok=True,
            verbose=False # OCR ë¡œê·¸ì— ì§‘ì¤‘í•˜ê¸° ìœ„í•´ YOLO ë¡œê·¸ëŠ” ë•ë‹ˆë‹¤
        )
        
        target_id = self.class_map.get(target_class)
        if target_id is None:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ê²Ÿ í´ë˜ìŠ¤ì…ë‹ˆë‹¤: {target_class}")
            return False

        # 3. OpenCVë¡œ ì›ë³¸ ì´ë¯¸ì§€ ì½ê¸° (í¬ë¡­ìš©)
        img = cv2.imread(str(screenshot_path))
        print(f"\nğŸ” '{target_text}' í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ '{target_class}'ë¥¼ ì°¾ëŠ” ì¤‘...")
        
        for box in results[0].boxes:
            if int(box.cls[0]) == target_id:
                # ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                
                # ì´ë¯¸ì§€ í¬ë¡­ (ì˜ë¼ë‚´ê¸°)
                cropped_img = img[y1:y2, x1:x2]
                
                # ë…¸ì´ì¦ˆ(ë„ˆë¬´ ì‘ì€ ë°•ìŠ¤) ë¬´ì‹œ
                if cropped_img.shape[0] < 5 or cropped_img.shape[1] < 5:
                    continue

                # 4. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
                ocr_result = self.reader.readtext(cropped_img, detail=0)
                extracted_text = " ".join(ocr_result).upper().replace(" ", "")
                compare_text = target_text.upper().replace(" ", "")
                
                # 5. í…ìŠ¤íŠ¸ ì¼ì¹˜ í™•ì¸ ë° í´ë¦­
                if compare_text in extracted_text:
                    center_x = float(box.xywh[0][0])
                    center_y = float(box.xywh[0][1])
                    
                    print(f"âœ… ë¹™ê³ ! '{extracted_text}' ë°œê²¬. (í™•ì‹ ë„: {float(box.conf[0]):.2f}) -> ì¢Œí‘œ ({center_x:.1f}, {center_y:.1f}) í´ë¦­!")
                    page.mouse.move(center_x, center_y)
                    page.mouse.down()
                    page.mouse.up()
                    return True
                    
        print(f"âŒ í™”ë©´ì—ì„œ '{target_text}'ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return False